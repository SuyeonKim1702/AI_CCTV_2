{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "TRAINING_FILE = 'training_file.txt'\n",
    "VALIDATION_FILE = 'validate_file.txt'\n",
    "\n",
    "\n",
    "learning_rate= 0.0001\n",
    "image_size= 96\n",
    "image_color= 3\n",
    "batch_size=100\n",
    "num_classes=3\n",
    "maxpool_filter_size= 2\n",
    "log_dir='C:\\\\Users\\\\td170\\\\' \n",
    "\n",
    "#conv_1\n",
    "conv1_filter_size = 3\n",
    "conv1_layer_size = 16\n",
    "stride1 = 1\n",
    "\n",
    "#conv_2\n",
    "conv2_filter_size = 3\n",
    "conv2_layer_size = 32\n",
    "stride2 = 1\n",
    "\n",
    "#conv_3\n",
    "conv3_filter_size = 3\n",
    "conv3_layer_size = 64\n",
    "stride3 = 1\n",
    "\n",
    "#conv_4\n",
    "conv4_filter_size = 5\n",
    "conv4_layer_size = 128\n",
    "stride4 = 1\n",
    "\n",
    "#fc_1\n",
    "input_layer_size = 6*6*conv3_layer_size\n",
    "fc1_layer_size = 512\n",
    "\n",
    "#fc_2\n",
    "fc2_layer_size = 256\n",
    "\n",
    "\n",
    "\n",
    "def get_input_queue(csv_file_name,num_epochs = None):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for line in open(csv_file_name,'r'):\n",
    "        cols = re.split(',|\\n',line)\n",
    "        train_images.append(cols[0])\n",
    "        \n",
    "        # 3rd column is label and needs to be converted to int type\n",
    "        train_labels.append(int(cols[2]))\n",
    "        \n",
    "                            \n",
    "    input_queue = tf.train.slice_input_producer([train_images,train_labels],\n",
    "                                               num_epochs = num_epochs,shuffle = True)\n",
    "    \n",
    "    return input_queue\n",
    "\n",
    "def read_data(input_queue):\n",
    "    image_file = input_queue[0]\n",
    "    label = input_queue[1]\n",
    "    \n",
    "    image =  tf.image.decode_jpeg(tf.read_file(image_file),channels=image_color)\n",
    "    \n",
    "    return image,label,image_file\n",
    "\n",
    "def read_data_batch(csv_file_name,batch_size=batch_size):\n",
    "    input_queue = get_input_queue(csv_file_name)\n",
    "    image,label,file_name= read_data(input_queue)\n",
    "    image = tf.reshape(image,[image_size,image_size,image_color])\n",
    "    \n",
    "    # random image\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image,max_delta=0.5)\n",
    "    image = tf.image.random_contrast(image,lower=0.2,upper=2.0)\n",
    "    image = tf.image.random_hue(image,max_delta=0.08)\n",
    "    image = tf.image.random_saturation(image,lower=0.2,upper=2.0)\n",
    "    \n",
    "    batch_image,batch_label,batch_file = tf.train.batch([image,label,file_name],batch_size=batch_size)\n",
    "    #,enqueue_many=True)\n",
    "    batch_file = tf.reshape(batch_file,[batch_size,1])\n",
    "\n",
    "    batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),\n",
    "        num_classes, on_value=1.0, off_value=0.0)\n",
    "    return batch_image,batch_label_on_hot,batch_file\n",
    "\n",
    "# convolutional network layer 1\n",
    "def conv1(input_data):\n",
    "    # layer 1 (convolutional layer)\n",
    "    conv1_filter_size = 3\n",
    "    conv1_layer_size = 16\n",
    "    stride1 = 1\n",
    "    \n",
    "    with tf.name_scope('conv_1'):\n",
    "        W_conv1 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv1_filter_size,conv1_filter_size,image_color,conv1_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b1 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv1_layer_size],stddev=0.1))\n",
    "        h_conv1 = tf.nn.conv2d(input_data,W_conv1,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv1_relu = tf.nn.relu(tf.add(h_conv1,b1))\n",
    "        h_conv1_maxpool = tf.nn.max_pool(h_conv1_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv1_maxpool\n",
    "\n",
    "# convolutional network layer 2\n",
    "def conv2(input_data):\n",
    "    conv2_filter_size = 3\n",
    "    conv2_layer_size = 32\n",
    "    stride2 = 1\n",
    "    \n",
    "    with tf.name_scope('conv_2'):\n",
    "        W_conv2 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv2_filter_size,conv2_filter_size,conv1_layer_size,conv2_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b2 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv2_layer_size],stddev=0.1))\n",
    "        h_conv2 = tf.nn.conv2d(input_data,W_conv2,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv2_relu = tf.nn.relu(tf.add(h_conv2,b2))\n",
    "        h_conv2_maxpool = tf.nn.max_pool(h_conv2_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv2_maxpool\n",
    "\n",
    "# convolutional network layer 3\n",
    "def conv3(input_data):\n",
    "    conv3_filter_size = 3\n",
    "    conv3_layer_size = 64\n",
    "    stride3 = 1\n",
    "    \n",
    "    print ('## FLAGS.stride1 ',stride1)\n",
    "    with tf.name_scope('conv_3'):\n",
    "        W_conv3 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv3_filter_size,conv3_filter_size,conv2_layer_size,conv3_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b3 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv3_layer_size],stddev=0.1))\n",
    "        h_conv3 = tf.nn.conv2d(input_data,W_conv3,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv3_relu = tf.nn.relu(tf.add(h_conv3,b3))\n",
    "        h_conv3_maxpool = tf.nn.max_pool(h_conv3_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv3_maxpool\n",
    "\n",
    "# convolutional network layer 3\n",
    "def conv4(input_data):\n",
    "    conv4_filter_size = 5\n",
    "    conv4_layer_size = 128\n",
    "    stride4 = 1\n",
    "    \n",
    "    with tf.name_scope('conv_4'):\n",
    "        W_conv4 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv4_filter_size,conv4_filter_size,conv3_layer_size,conv4_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b4 = tf.Variable(tf.truncated_normal(\n",
    "                        [conv4_layer_size],stddev=0.1))\n",
    "        h_conv4 = tf.nn.conv2d(input_data,W_conv4,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv4_relu = tf.nn.relu(tf.add(h_conv4,b4))\n",
    "        h_conv4_maxpool = tf.nn.max_pool(h_conv4_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv4_maxpool\n",
    "\n",
    "# fully connected layer 1\n",
    "def fc1(input_data):\n",
    "    input_layer_size = 6*6*conv4_layer_size\n",
    "    fc1_layer_size = 512\n",
    "    \n",
    "    with tf.name_scope('fc_1'):\n",
    "        # 앞에서 입력받은 다차원 텐서를 fcc에 넣기 위해서 1차원으로 피는 작업\n",
    "        input_data_reshape = tf.reshape(input_data, [-1, input_layer_size])\n",
    "        W_fc1 = tf.Variable(tf.truncated_normal([input_layer_size,fc1_layer_size],stddev=0.1))\n",
    "        b_fc1 = tf.Variable(tf.truncated_normal(\n",
    "                        [fc1_layer_size],stddev=0.1))\n",
    "        h_fc1 = tf.add(tf.matmul(input_data_reshape,W_fc1) , b_fc1) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        h_fc1_relu = tf.nn.relu(h_fc1)\n",
    "    \n",
    "    return h_fc1_relu\n",
    "    \n",
    "# fully connected layer 2\n",
    "def fc2(input_data):\n",
    "    fc2_layer_size = 256\n",
    "    \n",
    "    with tf.name_scope('fc_2'):\n",
    "        W_fc2 = tf.Variable(tf.truncated_normal([fc1_layer_size,fc2_layer_size],stddev=0.1))\n",
    "        b_fc2 = tf.Variable(tf.truncated_normal(\n",
    "                        [fc2_layer_size],stddev=0.1))\n",
    "        h_fc2 = tf.add(tf.matmul(input_data,W_fc2) , b_fc2) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        h_fc2_relu = tf.nn.relu(h_fc2)\n",
    "    \n",
    "    return h_fc2_relu\n",
    "\n",
    "# final layer\n",
    "def final_out(input_data):\n",
    "\n",
    "    with tf.name_scope('final_out'):\n",
    "        W_fo = tf.Variable(tf.truncated_normal([fc2_layer_size,num_classes],stddev=0.1))\n",
    "        b_fo = tf.Variable(tf.truncated_normal(\n",
    "                        [num_classes],stddev=0.1))\n",
    "        h_fo = tf.add(tf.matmul(input_data,W_fo) , b_fo) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        \n",
    "    # 최종 레이어에 softmax 함수는 적용하지 않았다. \n",
    "        \n",
    "    return h_fo\n",
    "\n",
    "# build cnn_graph\n",
    "def build_model(images,keep_prob):\n",
    "    # define CNN network graph\n",
    "    # output shape will be (*,48,48,16)\n",
    "    r_cnn1 = conv1(images) # convolutional layer 1\n",
    "    print (\"shape after cnn1 \",r_cnn1.get_shape())\n",
    "    \n",
    "    # output shape will be (*,24,24,32)\n",
    "    r_cnn2 = conv2(r_cnn1) # convolutional layer 2\n",
    "    print (\"shape after cnn2 :\",r_cnn2.get_shape() )\n",
    "    \n",
    "    # output shape will be (*,12,12,64)\n",
    "    r_cnn3 = conv3(r_cnn2) # convolutional layer 3\n",
    "    print (\"shape after cnn3 :\",r_cnn3.get_shape() )\n",
    "\n",
    "    # output shape will be (*,6,6,128)\n",
    "    r_cnn4 = conv4(r_cnn3) # convolutional layer 4\n",
    "    print (\"shape after cnn4 :\",r_cnn4.get_shape() )\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    r_fc1 = fc1(r_cnn4)\n",
    "    print (\"shape after fc1 :\",r_fc1.get_shape() )\n",
    "\n",
    "    # fully connected layer2\n",
    "    r_fc2 = fc2(r_fc1)\n",
    "    print (\"shape after fc2 :\",r_fc2.get_shape() )\n",
    "    \n",
    "    ## drop out\n",
    "    # 참고 http://stackoverflow.com/questions/34597316/why-input-is-scaled-in-tf-nn-dropout-in-tensorflow\n",
    "    # 트레이닝시에는 keep_prob < 1.0 , Test 시에는 1.0으로 한다. \n",
    "    r_dropout = tf.nn.dropout(r_fc2,keep_prob)\n",
    "    print (\"shape after dropout :\",r_dropout.get_shape() ) \n",
    "    \n",
    "    # final layer\n",
    "    r_out = final_out(r_dropout)\n",
    "    print (\"shape after final layer :\",r_out.get_shape() )\n",
    "\n",
    "\n",
    "    return r_out \n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "    # define placeholders for image data & label for traning dataset\n",
    "    \n",
    "    images = tf.placeholder(tf.float32,[None,image_size,image_size,image_color])\n",
    "    labels = tf.placeholder(tf.int32,[None,num_classes])\n",
    "    image_batch,label_batch,file_batch = read_data_batch(TRAINING_FILE) \n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32) # dropout ratio\n",
    "    prediction = build_model(images,keep_prob)\n",
    "    # define loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=labels))\n",
    "\n",
    "    tf.summary.scalar('loss',loss)\n",
    "\n",
    "    #define optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "    # for validation\n",
    "    #with tf.name_scope(\"prediction\"):\n",
    " \n",
    "    validate_image_batch,validate_label_batch,validate_file_batch = read_data_batch(VALIDATION_FILE)\n",
    "    label_max = tf.argmax(labels,1)\n",
    "    pre_max = tf.argmax(prediction,1)\n",
    "    correct_pred = tf.equal(tf.argmax(prediction,1),tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "            \n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "        \n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    \n",
    "    #build the summary tensor based on the tF collection of Summaries\n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        saver = tf.train.Saver() # create saver to store training model into file\n",
    "        summary_writer = tf.summary.FileWriter('./log/',sess.graph)\n",
    "        \n",
    "        init_op = tf.global_variables_initializer() # use this for tensorflow 0.12rc0\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        for i in range(10000):\n",
    "            images_,labels_ = sess.run([image_batch,label_batch])\n",
    "            #sess.run(train_step,feed_dict={images:images_,labels:labels_,keep_prob:0.8})\n",
    "            sess.run(train,feed_dict={images:images_,labels:labels_,keep_prob:0.7})\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                now = datetime.now()-startTime\n",
    "                print('## time:',now,' steps:',i)         \n",
    "                \n",
    "                # print out training status\n",
    "                rt = sess.run([label_max,pre_max,loss,accuracy],feed_dict={images:images_ \n",
    "                                                          , labels:labels_\n",
    "                                                          , keep_prob:1.0})\n",
    "                print ('Prediction loss:',rt[2],' accuracy:',rt[3])\n",
    "                # validation steps\n",
    "                validate_images_,validate_labels_ = sess.run([validate_image_batch,validate_label_batch])\n",
    "                rv = sess.run([label_max,pre_max,loss,accuracy],feed_dict={images:validate_images_ \n",
    "                                                          , labels:validate_labels_\n",
    "                                                          , keep_prob:1.0})\n",
    "                print ('Validation loss:',rv[2],' accuracy:',rv[3])\n",
    "                if(rv[3] > 0.9):\n",
    "                    break\n",
    "                # validation accuracy\n",
    "                #summary_str = sess.run(summary,feed_dict={images:validate_images_ \n",
    "                                                         # , labels:validate_labels_\n",
    "                                                         # , keep_prob:1.0})\n",
    "                #summary_writer.add_summary(summary_str,i)\n",
    "                #summary_writer.flush()\n",
    "        \n",
    "        saver.save(sess, 'face_recog') # save session\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        print('finish')\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
